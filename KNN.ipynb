{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Nearest Neighbors Algorithm in Python #\n",
    "\n",
    "No we will try to use the KNN on real music data by rewriting it in python. \n",
    "The dataset we will use to start will be the [University of Iowa Musical Instrument Samples Dataset](http://theremin.music.uiowa.edu/index.html). The first two cells in this notebook will load the dataset for you. Make sure you have downloaded the `Iowa_MIS_dataset.mat` file and you have put it the same directory where this notebook lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Iowa_MIS_dataset = scipy.io.loadmat('Iowa_MIS_dataset.mat')\n",
    "data = Iowa_MIS_dataset['dat_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `data` is of size [660,88201], and is is already shuffled (it's always good to double check, just to make sure). The number of rows tells you the number of datapoints in the dataset, and the number of columns - 1 tells you the dimensionality of the dataset. The rightmost column in the matrix contains the labels for all datapoints. Possible labels are:\n",
    "\n",
    "0 'Bass'\n",
    "\n",
    "1 'Bassoon'\n",
    "\n",
    "2 'Cello'\n",
    "\n",
    "3 'Clarinet'\n",
    "\n",
    "4 'Flute'\n",
    "\n",
    "5 'Guitar'\n",
    "\n",
    "6 'Horn'\n",
    "\n",
    "7 'Sax'\n",
    "\n",
    "8 'Trombone'\n",
    "\n",
    "9 'Trumpet'\n",
    "\n",
    "10 'Viola'\n",
    "\n",
    "11 'Violin'\n",
    "\n",
    "Next, separate the datapoints into training (~80% of the data), validation (~10%), and test sets (~10%) (procedure should be very similar to what you did in Julia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general data parameters\n",
    "N = data.shape[0]\n",
    "D = data.shape[1]-1\n",
    "C = 12\n",
    "\n",
    "# your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in xrange(1,20,2):\n",
    "\n",
    "    num_correct = 0\n",
    "    for i in xrange(x_vl.shape[0]):\n",
    "\n",
    "        # calculate the L1 norm between each point that you used to train the model\n",
    "        # and each point that you use to validate the model.    \n",
    "        # your code here:\n",
    "\n",
    "        # obtain the indices that would sort the array in ascending order\n",
    "        # your code here:\n",
    "\n",
    "        # obtain the labels for the KNNs using their indices\n",
    "        # your code here:\n",
    "\n",
    "        # have the neighbors vote [hint: use the scipy function 'mode']\n",
    "        # your code here:\n",
    "        predicted_label = \n",
    "\n",
    "        if  int(predicted_label.mode[0]) == int(y_vl[i]):\n",
    "            num_correct += 1\n",
    "\n",
    "    print 'accuracy with ', k, 'nearest neighbors: ', num_correct/x_vl.shape[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the best accuracy that you obtained? Was it above chance?\n",
    "\n",
    "How could you make this model better?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
